{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KbWoOb4E1zH9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import ViTImageProcessor, ViTForImageClassification\n",
        "from transformers import TrainingArguments, Trainer\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "import json\n",
        "from datetime import datetime\n",
        "import wandb\n",
        "import random\n",
        "\n",
        "# Wandb 초기화 함수\n",
        "def init_wandb(project_name=\"robot-task-classifier\", run_name=None, config=None):\n",
        "    \"\"\"\n",
        "    Wandb 초기화\n",
        "\n",
        "    Args:\n",
        "        project_name: Wandb 프로젝트 이름\n",
        "        run_name: 실행 이름 (None이면 자동 생성)\n",
        "        config: 설정 딕셔너리\n",
        "    \"\"\"\n",
        "    if run_name is None:\n",
        "        run_name = f\"vit-base-{datetime.now().strftime('%Y%m%d-%H%M%S')}\"\n",
        "\n",
        "    wandb.init(\n",
        "        project=project_name,\n",
        "        name=run_name,\n",
        "        config=config,\n",
        "        tags=[\"ViT\", \"image-classification\", \"robot-tasks\"]\n",
        "    )\n",
        "\n",
        "    print(f\"Wandb 초기화 완료: {project_name}/{run_name}\")\n",
        "\n",
        "# 1. ViT 모델과 프로세서 로드\n",
        "def load_vit_model(num_classes, model_name=\"google/vit-base-patch16-224\"):\n",
        "    \"\"\"\n",
        "    ViT-Base 모델을 로드하고 분류 헤드를 커스터마이징\n",
        "    \"\"\"\n",
        "    print(f\"모델 로딩: {model_name}\")\n",
        "    print(f\"분류 클래스 수: {num_classes}\")\n",
        "\n",
        "    processor = ViTImageProcessor.from_pretrained(model_name)\n",
        "    model = ViTForImageClassification.from_pretrained(\n",
        "        model_name,\n",
        "        num_labels=num_classes,\n",
        "        ignore_mismatched_sizes=True\n",
        "    )\n",
        "\n",
        "    total_params = sum(p.numel() for p in model.parameters())\n",
        "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "    print(f\"모델 파라미터 수: {total_params:,}\")\n",
        "    print(f\"훈련 가능한 파라미터 수: {trainable_params:,}\")\n",
        "\n",
        "    # Wandb에 모델 정보 로깅\n",
        "    if wandb.run is not None:\n",
        "        wandb.log({\n",
        "            \"model/total_parameters\": total_params,\n",
        "            \"model/trainable_parameters\": trainable_params,\n",
        "            \"model/num_classes\": num_classes\n",
        "        })\n",
        "\n",
        "    return model, processor\n",
        "\n",
        "# 2. 커스텀 데이터셋 클래스\n",
        "class RobotHeadDataset(Dataset):\n",
        "    \"\"\"로봇 헤드 이미지 데이터셋 클래스\"\"\"\n",
        "\n",
        "    def __init__(self, image_paths, labels, processor, augment=False):\n",
        "        self.image_paths = image_paths\n",
        "        self.labels = labels\n",
        "        self.processor = processor\n",
        "        self.augment = augment\n",
        "\n",
        "        print(f\"데이터셋 생성 완료: {len(image_paths)}개 샘플, 증강: {augment}\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        try:\n",
        "            image = Image.open(self.image_paths[idx]).convert('RGB')\n",
        "\n",
        "            # 간단한 데이터 증강 (훈련 시에만)\n",
        "            if self.augment and random.random() > 0.5:\n",
        "                # 좌우 반전\n",
        "                image = image.transpose(Image.FLIP_LEFT_RIGHT)\n",
        "\n",
        "            inputs = self.processor(images=image, return_tensors=\"pt\")\n",
        "\n",
        "            return {\n",
        "                'pixel_values': inputs['pixel_values'].squeeze(),\n",
        "                'labels': torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "            }\n",
        "        except Exception as e:\n",
        "            print(f\"이미지 로드 실패: {self.image_paths[idx]}, 에러: {e}\")\n",
        "            return self.__getitem__(0)\n",
        "\n",
        "# 3. 데이터 분할 함수\n",
        "def prepare_and_split_data(data_folder, class_names, val_split=0.2, test_split=0.1, random_state=42):\n",
        "    \"\"\"\n",
        "    데이터 폴더에서 이미지를 로드하고 train/val/test로 분할\n",
        "\n",
        "    Args:\n",
        "        data_folder: 전체 데이터가 있는 폴더\n",
        "        class_names: 클래스 이름 리스트\n",
        "        val_split: 검증 데이터 비율\n",
        "        test_split: 테스트 데이터 비율 (선택사항)\n",
        "        random_state: 재현 가능한 분할을 위한 시드\n",
        "\n",
        "    Returns:\n",
        "        train_paths, train_labels, val_paths, val_labels, [test_paths, test_labels]\n",
        "    \"\"\"\n",
        "    print(f\"데이터 분할 시작: val={val_split}, test={test_split}\")\n",
        "\n",
        "    all_image_paths = []\n",
        "    all_labels = []\n",
        "    class_distribution = {}\n",
        "\n",
        "    # 전체 데이터 수집\n",
        "    supported_formats = ('.jpg', '.jpeg', '.png', '.bmp', '.tiff')\n",
        "\n",
        "    for class_idx, class_name in enumerate(class_names):\n",
        "        class_folder = os.path.join(data_folder, class_name)\n",
        "\n",
        "        if not os.path.exists(class_folder):\n",
        "            print(f\"경고: {class_folder} 폴더가 존재하지 않습니다.\")\n",
        "            continue\n",
        "\n",
        "        class_images = []\n",
        "        for img_file in os.listdir(class_folder):\n",
        "            if img_file.lower().endswith(supported_formats):\n",
        "                full_path = os.path.join(class_folder, img_file)\n",
        "                all_image_paths.append(full_path)\n",
        "                all_labels.append(class_idx)\n",
        "                class_images.append(img_file)\n",
        "\n",
        "        class_distribution[class_name] = len(class_images)\n",
        "        print(f\"  {class_name}: {len(class_images)}개 이미지\")\n",
        "\n",
        "    print(f\"총 {len(all_image_paths)}개 이미지 로드됨\")\n",
        "\n",
        "    # 첫 번째 분할: train + val vs test\n",
        "    if test_split > 0:\n",
        "        train_val_paths, test_paths, train_val_labels, test_labels = train_test_split(\n",
        "            all_image_paths, all_labels,\n",
        "            test_size=test_split,\n",
        "            random_state=random_state,\n",
        "            stratify=all_labels  # 클래스 비율 유지\n",
        "        )\n",
        "\n",
        "        # 두 번째 분할: train vs val\n",
        "        val_size_adjusted = val_split / (1 - test_split)  # 전체에서 test를 제외한 비율로 조정\n",
        "        train_paths, val_paths, train_labels, val_labels = train_test_split(\n",
        "            train_val_paths, train_val_labels,\n",
        "            test_size=val_size_adjusted,\n",
        "            random_state=random_state,\n",
        "            stratify=train_val_labels\n",
        "        )\n",
        "\n",
        "        print(f\"데이터 분할 완료:\")\n",
        "        print(f\"  훈련: {len(train_paths)}개 ({len(train_paths)/len(all_image_paths)*100:.1f}%)\")\n",
        "        print(f\"  검증: {len(val_paths)}개 ({len(val_paths)/len(all_image_paths)*100:.1f}%)\")\n",
        "        print(f\"  테스트: {len(test_paths)}개 ({len(test_paths)/len(all_image_paths)*100:.1f}%)\")\n",
        "\n",
        "        # Wandb에 데이터 분포 로깅\n",
        "        if wandb.run is not None:\n",
        "            wandb.log({\n",
        "                \"data/total_samples\": len(all_image_paths),\n",
        "                \"data/train_samples\": len(train_paths),\n",
        "                \"data/val_samples\": len(val_paths),\n",
        "                \"data/test_samples\": len(test_paths),\n",
        "                \"data/class_distribution\": class_distribution\n",
        "            })\n",
        "\n",
        "        return train_paths, train_labels, val_paths, val_labels, test_paths, test_labels\n",
        "\n",
        "    else:\n",
        "        # train vs val만 분할\n",
        "        train_paths, val_paths, train_labels, val_labels = train_test_split(\n",
        "            all_image_paths, all_labels,\n",
        "            test_size=val_split,\n",
        "            random_state=random_state,\n",
        "            stratify=all_labels\n",
        "        )\n",
        "\n",
        "        print(f\"데이터 분할 완료:\")\n",
        "        print(f\"  훈련: {len(train_paths)}개 ({len(train_paths)/len(all_image_paths)*100:.1f}%)\")\n",
        "        print(f\"  검증: {len(val_paths)}개 ({len(val_paths)/len(all_image_paths)*100:.1f}%)\")\n",
        "\n",
        "        # Wandb에 데이터 분포 로깅\n",
        "        if wandb.run is not None:\n",
        "            wandb.log({\n",
        "                \"data/total_samples\": len(all_image_paths),\n",
        "                \"data/train_samples\": len(train_paths),\n",
        "                \"data/val_samples\": len(val_paths),\n",
        "                \"data/class_distribution\": class_distribution\n",
        "            })\n",
        "\n",
        "        return train_paths, train_labels, val_paths, val_labels\n",
        "\n",
        "# 4. Wandb 연동 Trainer 클래스\n",
        "class WandbTrainer(Trainer):\n",
        "    \"\"\"Wandb 로깅이 통합된 커스텀 Trainer\"\"\"\n",
        "\n",
        "    def log(self, logs):\n",
        "        \"\"\"훈련 로그를 Wandb에 전송\"\"\"\n",
        "        super().log(logs)\n",
        "\n",
        "        if wandb.run is not None:\n",
        "            # 스텝별 로깅\n",
        "            wandb_logs = {}\n",
        "            for key, value in logs.items():\n",
        "                if isinstance(value, (int, float)):\n",
        "                    wandb_logs[f\"train/{key}\"] = value\n",
        "\n",
        "            if wandb_logs:\n",
        "                wandb.log(wandb_logs, step=self.state.global_step)\n",
        "\n",
        "# 5. 모델 훈련 함수 (Wandb 연동)\n",
        "def train_classifier_with_wandb(train_dataset, val_dataset, model, output_dir=\"./robot-task-classifier\", config=None):\n",
        "    \"\"\"\n",
        "    Wandb와 연동된 분류기 훈련\n",
        "    \"\"\"\n",
        "    # 기본 config 설정\n",
        "    if config is None:\n",
        "        config = {}\n",
        "\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=output_dir,\n",
        "        per_device_train_batch_size=config.get('batch_size', 16),\n",
        "        per_device_eval_batch_size=config.get('batch_size', 16),\n",
        "        num_train_epochs=config.get('num_epochs', 10),\n",
        "        learning_rate=config.get('learning_rate', 2e-5),\n",
        "        weight_decay=config.get('weight_decay', 0.01),\n",
        "        logging_steps=10,\n",
        "        evaluation_strategy=\"epoch\",\n",
        "        save_strategy=\"epoch\",\n",
        "        load_best_model_at_end=True,\n",
        "        metric_for_best_model=\"accuracy\",\n",
        "        greater_is_better=True,\n",
        "        warmup_steps=config.get('warmup_steps', 100),\n",
        "        fp16=True,\n",
        "        dataloader_num_workers=4,\n",
        "        remove_unused_columns=False,\n",
        "        report_to=\"wandb\" if wandb.run is not None else \"none\",  # Wandb 연동\n",
        "    )\n",
        "\n",
        "    def compute_metrics(eval_pred):\n",
        "        \"\"\"검증 메트릭 계산 및 Wandb 로깅\"\"\"\n",
        "        predictions, labels = eval_pred\n",
        "        predictions = np.argmax(predictions, axis=1)\n",
        "\n",
        "        accuracy = accuracy_score(labels, predictions)\n",
        "\n",
        "        # 클래스별 정확도 계산\n",
        "        class_accuracies = {}\n",
        "        for i, class_name in enumerate(config.get('class_names', [])):\n",
        "            class_mask = (labels == i)\n",
        "            if class_mask.sum() > 0:\n",
        "                class_acc = (predictions[class_mask] == labels[class_mask]).mean()\n",
        "                class_accuracies[f\"val_accuracy/{class_name}\"] = class_acc\n",
        "\n",
        "        metrics = {\"accuracy\": accuracy}\n",
        "\n",
        "        # Wandb에 클래스별 정확도 로깅\n",
        "        if wandb.run is not None and class_accuracies:\n",
        "            wandb.log(class_accuracies)\n",
        "\n",
        "        return metrics\n",
        "\n",
        "    # WandbTrainer 사용\n",
        "    trainer = WandbTrainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=val_dataset,\n",
        "        compute_metrics=compute_metrics,\n",
        "    )\n",
        "\n",
        "    print(\"=\" * 50)\n",
        "    print(\"훈련 시작 (Wandb 연동)\")\n",
        "    print(f\"훈련 데이터: {len(train_dataset)}개\")\n",
        "    print(f\"검증 데이터: {len(val_dataset)}개\")\n",
        "    print(f\"배치 크기: {training_args.per_device_train_batch_size}\")\n",
        "    print(f\"에폭 수: {training_args.num_train_epochs}\")\n",
        "    print(f\"학습률: {training_args.learning_rate}\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # 훈련 실행\n",
        "    trainer.train()\n",
        "\n",
        "    # 최종 모델 저장\n",
        "    trainer.save_model()\n",
        "    print(f\"모델이 {output_dir}에 저장되었습니다.\")\n",
        "\n",
        "    # Wandb에 최종 메트릭 로깅\n",
        "    if wandb.run is not None:\n",
        "        final_metrics = trainer.evaluate()\n",
        "        wandb.log({\"final/val_accuracy\": final_metrics.get(\"eval_accuracy\", 0)})\n",
        "\n",
        "    return trainer\n",
        "\n",
        "# 6. 모델 저장 및 로드 함수들 (기존과 동일)\n",
        "def save_model_and_config(model, processor, class_names, save_path):\n",
        "    \"\"\"모델, 프로세서, 설정을 함께 저장\"\"\"\n",
        "    print(f\"모델 저장 중: {save_path}\")\n",
        "\n",
        "    os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "    # 모델과 프로세서 저장\n",
        "    model.save_pretrained(save_path)\n",
        "    processor.save_pretrained(save_path)\n",
        "\n",
        "    # 설정 저장\n",
        "    config = {\n",
        "        \"class_names\": class_names,\n",
        "        \"num_classes\": len(class_names),\n",
        "        \"model_name\": \"google/vit-base-patch16-224\",\n",
        "        \"save_date\": datetime.now().isoformat(),\n",
        "        \"model_type\": \"ViT-Base\"\n",
        "    }\n",
        "\n",
        "    with open(os.path.join(save_path, \"config.json\"), \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(config, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "    # Wandb에 모델 저장\n",
        "    if wandb.run is not None:\n",
        "        artifact = wandb.Artifact(\n",
        "            name=\"robot-task-classifier\",\n",
        "            type=\"model\",\n",
        "            description=\"Trained ViT model for robot task classification\"\n",
        "        )\n",
        "        artifact.add_dir(save_path)\n",
        "        wandb.log_artifact(artifact)\n",
        "\n",
        "    print(\"저장 완료!\")\n",
        "\n",
        "def load_saved_model(save_path):\n",
        "    \"\"\"저장된 모델과 설정 로드\"\"\"\n",
        "    print(f\"모델 로드 중: {save_path}\")\n",
        "\n",
        "    with open(os.path.join(save_path, \"config.json\"), \"r\", encoding=\"utf-8\") as f:\n",
        "        config = json.load(f)\n",
        "\n",
        "    class_names = config[\"class_names\"]\n",
        "    model = ViTForImageClassification.from_pretrained(save_path)\n",
        "    processor = ViTImageProcessor.from_pretrained(save_path)\n",
        "\n",
        "    print(\"로드 완료!\")\n",
        "    return model, processor, class_names\n",
        "\n",
        "# 7. 예측 및 평가 함수\n",
        "def evaluate_model_with_wandb(model, test_dataset, processor, class_names):\n",
        "    \"\"\"테스트 데이터셋으로 모델 평가 및 Wandb 로깅\"\"\"\n",
        "    from torch.utils.data import DataLoader\n",
        "    from sklearn.metrics import confusion_matrix, classification_report\n",
        "    import seaborn as sns\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "    model.eval()\n",
        "    dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
        "\n",
        "    all_predictions = []\n",
        "    all_labels = []\n",
        "\n",
        "    print(\"테스트 데이터 평가 중...\")\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            outputs = model(batch['pixel_values'])\n",
        "            predictions = torch.argmax(outputs.logits, dim=-1)\n",
        "\n",
        "            all_predictions.extend(predictions.cpu().numpy())\n",
        "            all_labels.extend(batch['labels'].cpu().numpy())\n",
        "\n",
        "    # 정확도 계산\n",
        "    accuracy = accuracy_score(all_labels, all_predictions)\n",
        "    print(f\"테스트 정확도: {accuracy:.4f}\")\n",
        "\n",
        "    # 분류 보고서\n",
        "    report = classification_report(all_labels, all_predictions, target_names=class_names, output_dict=True)\n",
        "\n",
        "    # 혼동 행렬\n",
        "    cm = confusion_matrix(all_labels, all_predictions)\n",
        "\n",
        "    # Wandb 로깅\n",
        "    if wandb.run is not None:\n",
        "        # 정확도 로깅\n",
        "        wandb.log({\"test/accuracy\": accuracy})\n",
        "\n",
        "        # 클래스별 메트릭 로깅\n",
        "        for class_name in class_names:\n",
        "            if class_name in report:\n",
        "                wandb.log({\n",
        "                    f\"test/precision/{class_name}\": report[class_name]['precision'],\n",
        "                    f\"test/recall/{class_name}\": report[class_name]['recall'],\n",
        "                    f\"test/f1/{class_name}\": report[class_name]['f1-score']\n",
        "                })\n",
        "\n",
        "        # 혼동 행렬 시각화\n",
        "        plt.figure(figsize=(10, 8))\n",
        "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                   xticklabels=class_names, yticklabels=class_names)\n",
        "        plt.title('Confusion Matrix')\n",
        "        plt.ylabel('True Label')\n",
        "        plt.xlabel('Predicted Label')\n",
        "\n",
        "        wandb.log({\"test/confusion_matrix\": wandb.Image(plt)})\n",
        "        plt.close()\n",
        "\n",
        "    return accuracy, report\n",
        "\n",
        "# 8. 메인 실행 함수\n",
        "def main():\n",
        "    \"\"\"메인 실행 함수\"\"\"\n",
        "\n",
        "    # === 설정 ===\n",
        "    config = {\n",
        "        'class_names': [\"pick_and_place\", \"navigation\", \"manipulation\", \"inspection\", \"assembly\"],\n",
        "        'data_folder': \"data/all\",  # 전체 데이터가 있는 폴더\n",
        "        'val_split': 0.2,           # 검증 데이터 비율\n",
        "        'test_split': 0.1,          # 테스트 데이터 비율\n",
        "        'batch_size': 16,\n",
        "        'num_epochs': 10,\n",
        "        'learning_rate': 2e-5,\n",
        "        'weight_decay': 0.01,\n",
        "        'warmup_steps': 100,\n",
        "        'random_state': 42\n",
        "    }\n",
        "\n",
        "    model_save_path = \"./saved_models/robot_task_classifier\"\n",
        "\n",
        "    # === Wandb 초기화 ===\n",
        "    init_wandb(\n",
        "        project_name=\"robot-task-classifier\",\n",
        "        run_name=f\"vit-base-{datetime.now().strftime('%Y%m%d-%H%M%S')}\",\n",
        "        config=config\n",
        "    )\n",
        "\n",
        "    print(\"=\" * 60)\n",
        "    print(\"로봇 태스크 분류기 훈련 시작 (Wandb 연동)\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # === 모델 로드 ===\n",
        "    model, processor = load_vit_model(len(config['class_names']))\n",
        "\n",
        "    # === 데이터 준비 및 분할 ===\n",
        "    result = prepare_and_split_data(\n",
        "        config['data_folder'],\n",
        "        config['class_names'],\n",
        "        val_split=config['val_split'],\n",
        "        test_split=config['test_split'],\n",
        "        random_state=config['random_state']\n",
        "    )\n",
        "\n",
        "    if len(result) == 6:  # test 데이터도 있는 경우\n",
        "        train_paths, train_labels, val_paths, val_labels, test_paths, test_labels = result\n",
        "        has_test = True\n",
        "    else:  # test 데이터 없는 경우\n",
        "        train_paths, train_labels, val_paths, val_labels = result\n",
        "        has_test = False\n",
        "\n",
        "    if len(train_paths) == 0:\n",
        "        print(\"오류: 훈련 데이터가 없습니다.\")\n",
        "        return\n",
        "\n",
        "    # === 데이터셋 생성 ===\n",
        "    train_dataset = RobotHeadDataset(train_paths, train_labels, processor, augment=True)\n",
        "    val_dataset = RobotHeadDataset(val_paths, val_labels, processor, augment=False)\n",
        "\n",
        "    if has_test:\n",
        "        test_dataset = RobotHeadDataset(test_paths, test_labels, processor, augment=False)\n",
        "\n",
        "    # === 모델 훈련 ===\n",
        "    trainer = train_classifier_with_wandb(train_dataset, val_dataset, model, model_save_path, config)\n",
        "\n",
        "    # === 모델 저장 ===\n",
        "    save_model_and_config(model, processor, config['class_names'], model_save_path)\n",
        "\n",
        "    # === 테스트 평가 (선택사항) ===\n",
        "    if has_test:\n",
        "        print(\"\\n테스트 데이터셋 평가 중...\")\n",
        "        test_accuracy, test_report = evaluate_model_with_wandb(model, test_dataset, processor, config['class_names'])\n",
        "        print(f\"최종 테스트 정확도: {test_accuracy:.4f}\")\n",
        "\n",
        "    # Wandb 종료\n",
        "    wandb.finish()\n",
        "\n",
        "    print(\"=\" * 60)\n",
        "    print(\"훈련 완료!\")\n",
        "    print(f\"Wandb 대시보드에서 결과를 확인하세요: {wandb.run.url if wandb.run else 'N/A'}\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ]
}